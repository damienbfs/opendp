\documentclass{article}
\input{../../lib.sty}


\title{\texttt{fn make\_rappor}}
\author{Abigail Gentle}
\begin{document}

\maketitle



\contrib

Proves soundness of \rustdoc{measurements/fn}{make\_rappor} in \asOfCommit{mod.rs}{cfd1bec5}.

\section{Introduction}
RAPPOR is a protocol for local-differentially private frequency estimation. In the local model each user is guaranteed $\varepsilon$-differential privacy for their response. This is achieved by computing the \texttt{xor} of each input vector with a noise vector. Because the noise is added mechanically we can efficiently account for the bias introduced with the function \rustdoc{measurements/fn}{debias\_basic\_rappor}, which sums and normalises a vector of private outputs.

In the simplest case, each category is represented by an index $i\in[k]$, where $[k]=\{0,1,\ldots,k-1\}$, and each row with category $i$ is transformed into a one-hot vector which has 0's everywhere and a 1 at index $i$. Therefore the number of set bits in the input is 1, and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=1$

In order to estimate the frequencies of strings drawn from a potentially unbounded set, inputs can also be hashed onto a Bloom filter using $h<k$ hash functions. As such the number of set bits is at most $h$ and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=h$. As we demonstrate in Theorem~\ref{thm:privacy-parameter}, the privacy of the protocol will degrade linearly with the number of hash functions used (although the hash functions will make the life of an adversary trickier, as each bit set in the Bloom filter could map to multiple possible strings). 
\section{Hoare Triple}
\subsection{Preconditions}
\begin{itemize}
	\item Variable \texttt{input\_domain} must be of type \rustdoc{domains/struct}{BitVectorDomain}, with \texttt{max\_weight}.
	\item Variable \texttt{input\_metric} must be of type \rustdoc{metrics/struct}{DiscreteDistance}.
	\item Variable \texttt{f} must be of type \texttt{f64}.
    \item Variable \texttt{constant\_time} must be of type \texttt{bool}.
\end{itemize}

\subsection*{Pseudocode}
\begin{lstlisting}[language=Python, escapechar=|]
def make_rappor(f: float64, constant_time: bool):
    input_domain: BitVectorDomain
    input_metric: DiscreteDistance
    output_domain = BitVectorDomain
    output_measure = MaxDivergence(f64)
    
    if (f <= 0.0 or f > 1): |\label{line:range}|
        raise Exception("Probability must be in (0.0, 1]")
    
    m = input_domain.max_weight
    if m == None: 
        raise Exception("RAPPOR requires a maximum number of set bits")
    eps = (2*m)*log((2-f)/f)
    def privacy_map(d_in: IntDistance): |\label{line:map}|
        return eps
    def function(arg: BitVector) -> BitVector: |\label{line:fn}|
    	k = len(arg)
    	noise_vector = [bool.sample_bernoulli(f/2, constant_time) for _ in range(k)]
    	return xor(arg, noise_vector)
    
    return Measurement(input_domain, function, input_metric, output_measure, privacy_map)
\end{lstlisting}

\subsection*{Postcondition}
\validMeasurement{\texttt{(f, m, constant\_time)}}{\\ \texttt{make\_rappor}}


\section{Proof}
\begin{enumerate}
	\item Privacy guarantee
\begin{tcolorbox}
\begin{note}[Proof relies on correctness of Bernoulli sampler]
The following proof makes use of the following lemma that asserts the correctness of the Bernoulli sampler function.
    \begin{lemma}
    If system entropy is not sufficient, \texttt{sample\_bernoulli} raises an error. 
    Otherwise, \texttt{sample\_bernoulli(f/2, constant\_time)}, the Bernoulli sampler function used in \texttt{make\_randomized\_response\_bool}, 
    returns \texttt{true} with probability (\texttt{prob}) and returns  \texttt{false} with probability (1 - \texttt{f/2}).
    \end{lemma}
\end{note}
\end{tcolorbox}
\begin{theorem}~\cite{rappor}
\label{thm:privacy-parameter}
	\rustdoc{measurements/fn}{make\_rappor} satisfies $\varepsilon$-DP where 
	\begin{equation*}
		\varepsilon = 2m\log\left(\frac{2-f}{f}\right)
	\end{equation*}
\end{theorem}
\begin{lemma}
	\begin{align}
		P[y_i = 1~|~x_i=1] &= 1 - \frac{1}{2}f\\
		P[y_i = 1~|~x_i=0] &=\frac{1}{2}f
	\end{align}
\end{lemma}
\begin{proof}
	Let $Y=y_1,\ldots,y_k$ be a randomised report generated by \rustdoc{measurements/fn}{make\_rappor}. Then the probability of observing any given report $Y$ is $P[Y=y | X=x]$. $x=x_1,\ldots,x_k$ is a single Boolean vector with at most $m$ ones. 
	Without loss of generality assume that $x^*=\{x_1=1,\ldots,x_m=1,x_{m+1}=0,\ldots,x_k=0\}$, then we have
	\begin{align*}
		P[Y=y~|~X=x^*] &=%
			\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
			\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
	\end{align*}
	Then let $D$ be the ratio of two such conditional probabilities with distinct values $x_1$ and $x_2$, and let $S$ be the range of \rustdoc{measurements/fn}{make\_rappor}.
	\begin{align}
		D &= \frac{P[Y\in S~|~X=x_1]}{P[Y\in S~|~X=x_2]}\\
			&= \frac{\sum_{y\in S}P[Y=y~|~X=x_1]}{\sum_{y\in S}P[Y=y~|~X=x_2]}\nonumber\\
			&\leq \max_{y\in S}\frac{P[Y=y~|~X=x_1]}{P[Y=y~|~X=x_2]}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}\times%
				\prod\limits_{i=2m+1}^{k}\left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}
			}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}%
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}%
			}\label{eq:privacy:cancel-k}\\
			&=\max_{y\in S}\left[%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{2(1-y_i)}\left(1-\frac{1}{2}f\right)^{2y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{2y_i} \left(1-\frac{1}{2}f\right)^{2(1-y_i)}\right]\label{eq:maximise-product}%
	\end{align}
	Notice that by equation~\ref{eq:privacy:cancel-k} the privacy is not dependent on $k$ and equation~\ref{eq:maximise-product} is maximised when $y_1=1,\ldots,y_m=1$, and $y_{m+1},\ldots,y_{2m}=0$, giving
	\begin{align*}
		D &\leq \left(1-\frac{1}{2}f\right)^{2m}\times\left(\frac{1}{2}f\right)^{-2m}\\
			&= \left(\frac{2-f}{f}\right)^{2m}
	\end{align*}
	Therefore,
	\begin{equation}
		\varepsilon \leq 2m\log\left(\frac{2-f}{f}\right)
	\end{equation}
\end{proof}
\item Utility
\begin{theorem}
\label{thm:unbiased-estimator}
	\rustdoc{measurements/fn}{debias\_basic\_rappor} is an unbiased frequency estimator.
\end{theorem}
\begin{proof} We denote the input domain as $X$, which is the set of all vectors with hamming weight less than or equal to $m$. The set of all users is $X^n$, where each user $x_1,\ldots,x_j,\ldots,x_n$ holds a single input. Each input $x_j$ is transformed into $y_j$ using \rustdoc{measurements/fn}{make\_rappor}. Let $Y$ be the sum of $n$ received outputs, where $Y_i=\sum_{j=1}^n y_i$ is the number of received bits at index $i\in [k]$. Let $N_i=\sum x_{j,i}$ be the true (non-private) count vector of users with bit $i$ set. Our goal is to estimate the frequencies $q_i=N_i/n$ with minimal error. $Y_i$ is a sum of two binomials
\begin{align}
\mathbb{E}[Y_i] &= \mathbb{E}\left[\text{Bin}\left(N_i,1-\frac{f}{2}\right)+\text{Bin}\left(n-N_i,\frac{f}{2}\right)\right]\label{eq:YsumBin}\\
    &=N_i\left(1-\frac{1}{2}f\right) + (n-N_i)\frac{f}{2}\label{eq:expec-Y}
\end{align}
Therefore by rearranging~\ref{eq:expec-Y} we obtain an unbiased estimator for $\hat{N_i}$
\begin{equation}
    \label{eq:estimator}
    \hat{N_i} = \frac{Y_i-n\frac{f}{2}}{1-f}
\end{equation}

Our goal however, is to estimate the frequency of each element $\hat{q}_i$ so we need to normalise by dividing by $n$ which gives us
\[
\hat{q_i}=\frac{\mathbb{E}[\hat{N}_i]}{n} = \frac{\frac{Y_i}{n}-\frac{f}{2}}{1-f}
\]
\end{proof}
\begin{theorem}
	\rustdoc{measurements/fn}{debias\_basic\_rappor} is a frequency estimator with mean squared error
	\begin{equation*}
		\mathbb{E}[\ell_2^2(q-\hat{q})] = \frac{k\left(f-\frac{f^2}{2}\right)}{2n(1-f)^2}.
	\end{equation*}
\end{theorem}
\begin{proof}\hfill

Let $q = q(X^n)=\sum\limits_{j=1}^n x_j$ be the non private frequency vector of inputs, our goal is to find the mean squared error of our estimate from this vector. Using the fact from equation~\ref{eq:YsumBin} that $Y_i$ is a sum of two Binomials with equal variance (by the symmetry of their probabilities), we get
\begin{equation}
\label{eq:varianceY}
    \text{Var}(Y_i)=n\frac{f}{2}\left(1-\frac{f}{2}\right)
\end{equation}
	\begin{align*}
		\mathbb{E}[|\hat{q}-q|_2^2] &= \mathbb{E}\left[\sum\limits_{i=1}^k(\hat{q_i}-q_i)^2\right] = \sum\limits_{i=1}^k\mathbb{E}[(\hat{q_i}-q_i)^2] &&\\
			&= \sum\limits_{i=1}^k\mathbb{E}[(\hat{q_i}-\mathbb{E}[\hat{q_i}])^2] && \text{by Theorem~\ref{thm:unbiased-estimator}}\\
			&= \sum\limits_{i=1}^k\text{Var}(\hat{q_i}) = \sum\limits_{i=1}^k\text{Var}\left(\frac{\frac{\hat{Y_i}}{n}-\frac{f}{2}}{1-f}\right)&&\text{by Equation~\ref{eq:estimator}}\\
			&= \sum\limits_{i=1}^k\text{Var}\left(\frac{Y_i}{n(1-f)}\right) &&\\
			&= \sum\limits_{i=1}^k\frac{\text{Var}(Y_i)}{n^2(1-f)^2}&&\\
			&= k\left(\frac{n\frac{f}{2}\left(1-\frac{f}{2}\right)}{n^2(1-f)^2}\right) &&\text{ by Equation~\ref{eq:varianceY}}\\
			& = \frac{k\left(f-\frac{f^2}{2}\right)}{2n(1-f)^2}&&
	\end{align*}
	
\end{proof}
\end{enumerate}

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}