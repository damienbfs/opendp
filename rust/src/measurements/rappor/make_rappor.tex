\documentclass{article}
\input{../../lib.sty}


\title{\texttt{fn make\_rappor}}
\author{Abigail Gentle}
\begin{document}

\maketitle



\contrib

Proves soundness of \rustdoc{measurements/fn}{make\_rappor} in \asOfCommit{mod.rs}{cfd1bec5}.

\section{Introduction}
RAPPOR is a protocol for local-differentially private frequency estimation. In the local model each user is guaranteed $\varepsilon$-differential privacy for their response. This is achieved by computing the \texttt{xor} of each input vector with a noise vector. Because the noise is added mechanically we can efficiently account for the bias introduced with the function \rustdoc{measurements/fn}{debias\_basic\_rappor}, which sums and normalises a vector of private outputs.

In the simplest case, each category is represented by an index $i\in[k]$, where $[k]=\{0,1,\ldots,k-1\}$, and each row with category $i$ is transformed into a one-hot vector which has 0's everywhere and a 1 at index $i$. Therefore the number of set bits in the input is 1, and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=1$

In order to estimate the frequencies of strings drawn from a potentially unbounded set, inputs can also be hashed onto a Bloom filter using $h<k$ hash functions. As such the number of set bits is at most $h$ and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=h$. As we demonstrate in Theorem~\ref{thm:privacy-parameter}, the privacy of the protocol will degrade linearly with the number of hash functions used (although the hash functions will make the life of an adversary trickier, as each bit set in the Bloom filter could map to multiple possible strings). 
\section{Hoare Triple}
\subsection{Preconditions}
\begin{itemize}
	\item Variable \texttt{input\_domain} must be of type \rustdoc{domains/struct}{BitVectorDomain}, with \texttt{max\_weight}.
	\item Variable \texttt{input\_metric} must be of type \rustdoc{metrics/struct}{DiscreteDistance}.
	\item Variable \texttt{f} must be of type \texttt{f64}.
    \item Variable \texttt{constant\_time} must be of type \texttt{bool}.
\end{itemize}

\subsection*{Pseudocode}
\begin{lstlisting}[language=Python, escapechar=|]
def make_rappor(f: float64, constant_time: bool):
    input_domain: BitVectorDomain
    input_metric: DiscreteDistance
    output_domain = BitVectorDomain
    output_measure = MaxDivergence(f64)
    
    if (f <= 0.0 or f > 1): |\label{line:range}|
        raise Exception("Probability must be in (0.0, 1]")
    
    m = input_domain.max_weight
    if m == None: 
        raise Exception("RAPPOR requires a maximum number of set bits")
    eps = (2*m)*log((2-f)/f)
    def privacy_map(d_in: IntDistance): |\label{line:map}|
        return eps
    def function(arg: BitVector) -> BitVector: |\label{line:fn}|
    	k = len(arg)
    	noise_vector = [bool.sample_bernoulli(f/2, constant_time) for _ in range(k)]
    	return xor(arg, noise_vector)
    
    return Measurement(input_domain, function, input_metric, output_measure, privacy_map)
\end{lstlisting}

\subsection*{Postcondition}
\validMeasurement{\texttt{(f, m, constant\_time)}}{\\ \texttt{make\_rappor}}


\section{Proof}
\begin{enumerate}
	\item Privacy guarantee
\begin{tcolorbox}
\begin{note}[Proof relies on correctness of Bernoulli sampler]
The following proof makes use of the following lemma that asserts the correctness of the Bernoulli sampler function.
    \begin{lemma}
    If system entropy is not sufficient, \texttt{sample\_bernoulli} raises an error. 
    Otherwise, \texttt{sample\_bernoulli(f/2, constant\_time)}, the Bernoulli sampler function used in \texttt{make\_randomized\_response\_bool}, 
    returns \texttt{true} with probability (\texttt{prob}) and returns  \texttt{false} with probability (1 - \texttt{f/2}).
    \end{lemma}
\end{note}
\end{tcolorbox}
\begin{theorem}~\cite{rappor}
\label{thm:privacy-parameter}
	\rustdoc{measurements/fn}{make\_rappor} satisfies $\varepsilon$-DP where 
	\begin{equation*}
		\varepsilon = 2m\log\left(\frac{2-f}{f}\right)
	\end{equation*}
\end{theorem}
\begin{lemma}
	\begin{align}
		P[y_i = 1~|~x_i=1] &= 1 - \frac{1}{2}f\\
		P[y_i = 1~|~x_i=0] &=\frac{1}{2}f
	\end{align}
\end{lemma}
\begin{proof}
	Let $Y=y_1,\ldots,y_k$ be a randomised report generated by \rustdoc{measurements/fn}{make\_rappor}. Then the probability of observing any given report $Y$ is $P[Y=y | X=x]$. $x=x_1,\ldots,x_k$ is a single Boolean vector with at most $m$ ones. 
	Without loss of generality assume that $x^*=\{x_1=1,\ldots,x_m=1,x_{m+1}=0,\ldots,x_k=0\}$, then we have
	\begin{align*}
		P[Y=y~|~X=x^*] &=%
			\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
			\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
	\end{align*}
	Then let $D$ be the ratio of two such conditional probabilities with distinct values $x_1$ and $x_2$, and let $S$ be the range of \rustdoc{measurements/fn}{make\_rappor}.
	\begin{align}
		D &= \frac{P[Y\in S~|~X=x_1]}{P[Y\in S~|~X=x_2]}\\
			&= \frac{\sum_{y\in S}P[Y=y~|~X=x_1]}{\sum_{y\in S}P[Y=y~|~X=x_2]}\nonumber\\
			&\leq \max_{y\in S}\frac{P[Y=y~|~X=x_1]}{P[Y=y~|~X=x_2]}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}\times%
				\prod\limits_{i=2m+1}^{k}\left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}
			}\nonumber\\
			%&=\max_{y\in S}\frac{%
			%	\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
			%	\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}%
			%	\times \prod\limits_{i=2m+1}^{k}\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
			%}{%
				%\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				%\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}%
				%\times\prod\limits_{i=2m+1}^{k}\left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}
			%}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}%
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}%
			}\label{eq:privacy:cancel-k}\\
			&=\max_{y\in S}\left[%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{2(1-y_i)}\left(1-\frac{1}{2}f\right)^{2y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{2y_i} \left(1-\frac{1}{2}f\right)^{2(1-y_i)}\right]\label{eq:maximise-product}%
	\end{align}
	Notice that by equation~\ref{eq:privacy:cancel-k} the privacy is not dependent on $k$ and equation~\ref{eq:maximise-product} is maximised when $y_1=1,\ldots,y_m=1$, and $y_{m+1},\ldots,y_{2m}=0$, giving
	\begin{align*}
		D &\leq \left(1-\frac{1}{2}f\right)^{2m}\times\left(\frac{1}{2}f\right)^{-2m}\\
			&= \left(\frac{2-f}{f}\right)^{2m}
	\end{align*}
	Therefore,
	\begin{equation}
		\varepsilon \leq 2m\log\left(\frac{2-f}{f}\right)
	\end{equation}
\end{proof}
\item Utility
\begin{theorem}
\label{thm:unbiased-estimator}
	The expected value of \rustdoc{measurements/fn}{debias\_basic\_rappor} is $N$.
\end{theorem}
\begin{proof} Each user, or row in the database $x$ represented as a vector with at most $m$ bits set is encoded into $y$ using \rustdoc{measurements/fn}{make\_rappor}. Let $Y$ be the sum of  $n$ received randomised outputs, where $Y_i=\sum_{j=1}^n y_i$ is the number of received bits at index $i\in [k]$. Let $N_i$ be the true (non-private) count of users with bit $i$ set in their input.
\begin{align}
\mathbb{E}[Y_i] &= N_i\left(1-\frac{1}{2}f\right) + (n-N_i)\frac{f}{2}\nonumber\\
	&= N_i(1-f) + n\frac{1}{2}f\nonumber\\
	\intertext{Therefore the estimator $\hat{N_i}$ given by}
\hat{N_i} &= \frac{Y_i-n\frac{f}{2}}{1-f}\label{eq:estimator}\\
\intertext{is unbiased as,}
\mathbb{E}[\hat{N_i}] &= N_i
\end{align}
\end{proof}
\begin{theorem}
	\rustdoc{measurements/fn}{debias\_basic\_rappor} has mean squared error
	\begin{equation*}
		l_2^2(N-\hat{N}) = kn\left(\frac{f^2-2f}{4(f-1)}\right)
	\end{equation*}
\end{theorem}
\begin{proof}\hfill
Notice that each $\hat{Y_i}$ is a sum of $n$ Bernoulli random variables with probability $1-\frac{1}{2}f$ or $\frac{1}{2}f$, which both have $\sigma^2 = \frac{1}{2}f\left(1-\frac{1}{2}f\right) = \frac{f}{2}-\frac{f^2}{4}$
	\begin{align*}
		\mathbb{E}[|\hat{N}-N|_2^2] &= \mathbb{E}\left[\sum\limits_{i=1}^k(\hat{N_i}-N_i)^2\right] = \sum\limits_{i=1}^k\mathbb{E}[(\hat{N_i}-N_i)^2] &&\\
			&= \sum\limits_{i=1}^k\mathbb{E}[(\hat{N_i}-\mathbb{E}[\hat{N_i}])^2] && \text{by Theorem~\ref{thm:unbiased-estimator}}\\
			&= \sum\limits_{i=1}^k\text{Var}(\hat{N_i}) = \sum\limits_{i=1}^k\frac{\text{Var}(\hat{Y_i})}{1-f}&&\text{by Equation~\ref{eq:estimator}}\\
			&= \sum\limits_{i=1}^kn\left(\frac{\frac{f}{2}-\frac{f^2}{4}}{1-f}\right) &&\\
			&= kn\left(\frac{f^2-2f}{4(f-1)}\right)
	\end{align*}
	
\end{proof}
\end{enumerate}

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}