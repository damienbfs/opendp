\documentclass{article} % necessary for Overleaf to recognize the file
\input{../../lib.sty} % `rust/src/lib.sty` contains boilerplate and macros

\title{\texttt{fn make\_permute\_and\_flip}}
\author{Tudor Cebere}\date{}

\begin{document}
\maketitle\contrib
This document proves soundness of \rustdoc{measurements}{make\_permute\_and\_flip} \cite{mckenna2020permute} in \asOfCommit{mod.rs}{e62b0aa2}. \texttt{make\_permut\_and\_flip} returns a Measurement that noisily selects the index of the greatest score from a vector of input scores. This released index can later be used to index into a public candidate set (postprocessing).

\subsection*{Vetting history}
\begin{itemize}
    \item \vettingPR{1678}
\end{itemize}

It is appealing to implement permute and flip due to its discrete nature.
The algorithm requires two primitives that need to be carefully implemented to work out using floating point arithmetics:
\begin{enumerate}
    \item A shuffling algorithm to shuffle the order in which the elements are being analysed. This is implemented via the Fisher-Yates shuffling algorithm, and it requires uniformly selecting an integer from a set, implemented using SampleIntBelow.
    \item A exact bernoulli sampler for distributions of the form $Bern(exp(-\gamma))$. The naive technique would require computing the binary expansions of $exp(-\gamma)$. We bypass this issue by using the exact sampler presented in section 5.2 in \cite{canonne2020discrete}, essentially reducing sampling $Bern(exp(-\gamma))$ to sampling $Bern(\frac{\gamma}{k}), \\ k \in N_{+}$, for which Bernoulli factories are known.
\end{enumerate}

Permute and flip is equivalent to report noisy max with exponential noise \cite{ding2021permute}. Implementation-wise, we will follow permute-and-flip, yet proving the correctness of the algorithm will be done via this equivalence.
\subsection*{Metric}

Permute and fip reuses the same metric as \rustdoc{measurements/gumbel_max}{RNM-gumbel}.

\section{Hoare Triple}
\subsection*{Preconditions}
\begin{itemize}
    \item \texttt{TIA} (input atom type) is a type with traits \rustdoc{traits/trait}{Number} and \rustdoc{traits/samplers/trait}{CastInternalRational}
    \item \texttt{QO} (output distance type) is a type with traits \rustdoc{traits/trait}{Float}, 
    \rustdoc{traits/samplers/trait}{CastInternalRational} and
    \rustdoc{traits/trait}{DistanceConstant} from type \texttt{TIA}
\end{itemize}

\subsection*{Pseudocode}
\label{sec:python-pseudocode}
\lstinputlisting[language=Python,firstline=2]{./pseudocode/make_permute_and_flip.py}

\subsection*{Postcondition}
\validMeasurement{\texttt{input\_domain, input\_metric, scale, optimize, TIA, QO}}{\texttt{make\_permute\_and\_flip}}

\section{Proof}

Before proving the privacy guarantees, we state a few required definitions and lemmas:
\begin{definition}
    \label{definition:rnm-exp}
 Report noisy max with exponential noise computes the index of the maximum element from a set of candidates $u \in \din $, add isotropic exponential noise $Z \sim Exp(1/\lambda)$ to each element in the candidate set $u$ and returns the maximum index as follows:
   \begin{equation}
 \texttt{RNM-Exp}(u) = argmax(u + Z), Z \sim Exp(1/\lambda \mathbb{I}_d)
   \end{equation} 
\end{definition}

\begin{lemma}
    \label{lemma:equivalence_pf_rnme}
 The permute-and-flip mechanism is equivalent to the report-noisy-max with exponential noise mechanism. Providing proof for this is out of the scope of this document; the details on this equivalence are presented in \cite{ding2021permute}. The pseudocode for report noisy max with exponential noise is implemented in Algorithm \ref{sec:python-rnme-pseudocode} for completeness.
\end{lemma}


\begin{lemma}
    \label{lemma:diff_cdf}
 Let $X_1, X_2 \sim Exp(\lambda), \Delta \geq 0$, then 
    \begin{equation}
 Pr[X_1 - X_2 \geq \Delta] = e^{-\Delta\lambda} Pr[X_1 - X_2 \geq 0]  
    \end{equation}

    \begin{proof}
        \begin{align}
        & Pr[X_1 - X_2 \geq \Delta] \\
        & = 1 - Pr[X_1 \geq \Delta + X_2]  && \text{by Law of Total Probability}\\
        & = 1 - \int^\infty_0 Pr[X_1 \geq \Delta + X_2 | X_2 = x] Pr[X_2 = x] dx  \\
        & = 1 - \int^\infty_0 Pr[X_1 \geq \Delta + x]Pr[X_2 = x] dx  && \text{by the fact that } \Delta >0 \\
        & = 1 - \int^\infty_0 \lambda(1 - e^{-(x + \Delta)\lambda})e^{-x\lambda}dx  \\
        & = 1 - \lambda \int^\infty_0 e^{-x\lambda} dx + \lambda e^{-\Delta\lambda} \int_0^\infty e^{-2x\lambda}dx \\
        & = 1 - 1 + e^{-\Delta\lambda} / 2 && \text{Observe $Pr[X_1 - X_2 \geq 0] = 1/2$} \\
        & = e ^{-\Delta\lambda} Pr[X_1 - X_2 \geq 0] 
    \end{align}
    \end{proof}
\end{lemma}

\newcommand\logeq{\mathrel{\vcentcolon\Leftrightarrow}}

\begin{theorem}
 The permute-and-flip mechanism (a.k.a \texttt{function}) satisfies $(\epsilon, 0)$-DP
\end{theorem}

\begin{proof}
 Let $u, v \in \texttt{input\_domain}$ be two candidate sets associated with input neighbouring datasets $D$, respectively $D'$. Assume $u$, $v$ in \texttt{input\_domain} are \din-close under \rustdoc{metrics/struct}{LInfDistance} and $\texttt{privacy\_map}(\din) \le \dout$.  We will proceed by proving both directions of the differential privacy inequality:

    \begin{align}
        & Pr[\texttt{function}(u) = i] \geq e^{-\epsilon}Pr[\texttt{function}(v) = i], \forall i \in [m] \iff  && \text{by Lemma \ref{lemma:equivalence_pf_rnme}} \\  
        & Pr[\texttt{RNM-Exp(u)} = i] \geq e^{-\epsilon}Pr[\texttt{RNM-Exp}(v) = i], \forall i \in [m] \iff && \text{by Definition \ref{definition:rnm-exp}} \\
        & Pr[\text{argmax}_k(u_k + Z_k) = i] \geq e^{-\epsilon}Pr[\text{argmax}_k(v_k + Z_k) = i], \forall i \in [m] && \\
 \intertext{Where $Z_k \sim \texttt{Exp}(1/\lambda)$. Let $Z^* = min_{Z_i} \{ u_i + Z_i \geq u_j + Z_j \}, \forall i \neq j$. Observe that for a fixed $i$, report noisy max outputs $i$ if:}
        & u_i + Z^* \geq u_j + Z_j, \forall i \neq j \iff \\
        & u_i + (v_i - v_i) + Z^* \geq u_j + (v_j - v_j) + Z_j \iff \\
        & v_i + (u_i - v_i) + Z^* \geq v_j + (u_j - v_j) + Z_j \iff \\ 
        & v_i + ((u_i - v_i) -(u_j - v_j) + Z^*) \geq v_j + Z_j \iff \\
        & v_i + (\Delta + Z^*) \geq v_j + Z_j
 \intertext{In other words, if $Z_i \geq (\Delta + Z^*)$, then $\texttt{function}(u) = \texttt{function}(v) = i$. Switching to a probability bound:}
        & Pr[\texttt{function}(v) = i]  = Pr[Z_i \geq \Delta + Z^*] && \text{by Lemma \ref{lemma:diff_cdf}}\\
        & \geq e^{-\Delta/\lambda} Pr[Z_i \geq Z^*] && \text{by the definition of $Z^*$} \\
        & = e^{-\Delta / \lambda} Pr[\texttt{function}(u) = i] && \text{Set } \lambda = \Delta / \epsilon \\
        & = e^{-\epsilon} Pr[\texttt{function}(u)] \iff \\
        & Pr[\texttt{function}(v) = i] \geq e^{-\epsilon} Pr[\texttt{function}(u)] \iff \\
        & \log \frac{Pr[\texttt{function}(u) = i]}{Pr[\texttt{function}(u) = i]} \leq \epsilon \\
        & = \dout && \text{by } \texttt{RangeDistance}\\
 \intertext{The inverse case follows by symmetry, completing the proof. It has been shown that $\function(u)$ and $\function(v)$ are \dout-close under \texttt{output\_measure} 
 under the definitions of $\function$ and \texttt{privacy\_map}, 
 and the conditions on the input distance and privacy map.}
    \end{align}
\end{proof}

\label{sec:python-rnme-pseudocode}
\lstinputlisting[language=Python,firstline=2]{./pseudocode/report_noisy_max_exponential.py}

\bibliographystyle{plain}
\bibliography{references.bib}

\end{document}