{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential and Parallel Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will: \n",
    "- Define sequential composition and parallel composition.\n",
    "- Illustrate sequential composition and parallel composition in practice through polars queries.\n",
    "- Compare and contrast sequential and parallel composition.\n",
    "\n",
    "Sources: [Textbook](https://programming-dp.com/ch4.html), [Paper](https://eprint.iacr.org/2021/1196.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition\n",
    "\n",
    "\n",
    "Before we get into the different types of composition, let's understand why composition is important and what it means. We will rarely only want one differentially private statistic; instead, we will compute multiple statistics on the same dataset. \n",
    "\n",
    "If we run many different differentially private algorithms on the same dataset, the resulting **composed** algorithm is also differentially private. So composition is a useful tool because it enables us to analyze the privacy properties of algorithms designed in this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terms\n",
    "\n",
    "1. **Noninteractive:** \n",
    "\n",
    "All queries are composed and executed at once. Specifically, take $F$ as a noninteractive algorithm composed of individual queries $F = \\text{Comp}(F_1, F_2, \\ldots, F_{k-1})$ and dataset x as the input dataset. $F(x)$ is our output, an algorithm that executes all the queries. \n",
    "\n",
    "2. **Interactive:** \n",
    "\n",
    "In an interactive algorithm, the queries are not defined in advance, and they can be determined based on the results from previous queries. This is an **adaptive** scenario. \n",
    "\n",
    "A non-adaptive scenario is where you simply want to compute statistics such as the mean, median, and sum of particular columns in a dataset. An adaptive scenario is where you start computing particular statistics about a column, such as \"income,\" and then change your queries depending on the results you find. For example, if you notice that the mean and median are extremely different, you may explore the distribution of the data. Otherwise, you may choose to focus your queries on other, more interesting aspects of your data. \n",
    "\n",
    "Interactive differential privacy is considered the \"right\" modeling for many applications since it captures the full capabilities of many fundamental DP mechanisms such as the Sparse Vector Technique. \n",
    "\n",
    "3. **Signal:**\n",
    "A large count = strong signal. A dataset with a large count likely won't be disrupted by adding weak noise, so higher utility (usefulness). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendp[polars] in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: polars==0.20.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendp[polars]) (0.20.16)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendp[polars]) (16.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendp[polars]) (1.5.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendp[polars]) (1.26.4)\n",
      "Requirement already satisfied: randomgen in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendp[polars]) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->opendp[polars]) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->opendp[polars]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->opendp[polars]) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"opendp[polars]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendp.prelude as dp\n",
    "import numpy as np\n",
    "import polars as pl \n",
    "\n",
    "dp.enable_features(\"contrib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv(\"sample_FR_LFS.csv\", infer_schema_length=1000, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = dp.Context.compositor(\n",
    "    data=df,\n",
    "    privacy_unit=dp.unit_of(contributions=36),\n",
    "    privacy_loss=dp.loss_of(epsilon=1.0),\n",
    "    split_evenly_over=10,\n",
    "    margins={\n",
    "        (\"ILOSTAT\", ): dp.Margin(public_info=\"lengths\", max_partition_length=60_000_000, max_num_partitions=3),\n",
    "        (\"YEAR\", \"QUARTER\", \"ILOSTAT\",): dp.Margin(public_info=\"lengths\", max_partition_length=60_000_000, max_partition_contributions=1, max_num_partitions=1),\n",
    "        (): dp.Margin(public_info=\"lengths\", max_partition_length=60_000_000, max_num_partitions=1),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential composition is a major property of differential privacy because it bounds the total privacy costs of computing multiple differentially private queries on the same data. It's important because it allows the design of algorithms that refer to the data multiple times. \n",
    "\n",
    "It's an extremely useful way to get an **upper** bound on the total ε of many queries, but keep in mind that the actual impact on privacy may be lower. Let's say that function 1, $F1$ satisfies ε-dp and function 2, $F2$, also satisfies ε-dp, then a mechanism where we compose functions $F1$ and $F2$, we get 2 * ε-dp.\n",
    "\n",
    "Sequential composition can be noninteractive and interactive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noninteractive Sequential Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute multiple queries at once using the `select` or `agg` methods. To start off, let's calculate the actual and differentially private mean and median for the variable `HWUSUAL`, which is the number of hours per week usually worked in the main job by respondents that were working for pay at the time of the survey.\n",
    "\n",
    "Notes: \n",
    "- Remember to reference the [EU Labour Force Survey User Guide](https://ec.europa.eu/eurostat/documents/1978984/6037342/EULFS-Database-UserGuide.pdf) for any questions about variables. \n",
    "- Do not calculate the actual mean to impute null values. We shouldn't reference our data after creating the compositor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/nlwnz_jj7rsblr2tzwj962b40000gn/T/ipykernel_41502/693093094.py:3: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
      "  actual_hours = df.groupby(\"ILOSTAT\").agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ILOSTAT</th><th>Mean Hours Worked</th><th>Median Hours Worked</th><th>Mean Hours Worked_right</th><th>Median Hours Worked_right</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>37.667898</td><td>37.0</td><td>36.397198</td><td>25</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌─────────┬───────────────────┬─────────────────────┬──────────────┬───────────────────────────┐\n",
       "│ ILOSTAT ┆ Mean Hours Worked ┆ Median Hours Worked ┆ Mean Hours   ┆ Median Hours Worked_right │\n",
       "│ ---     ┆ ---               ┆ ---                 ┆ Worked_right ┆ ---                       │\n",
       "│ i64     ┆ f64               ┆ f64                 ┆ ---          ┆ i64                       │\n",
       "│         ┆                   ┆                     ┆ f64          ┆                           │\n",
       "╞═════════╪═══════════════════╪═════════════════════╪══════════════╪═══════════════════════════╡\n",
       "│ 1       ┆ 37.667898         ┆ 37.0                ┆ 36.397198    ┆ 25                        │\n",
       "└─────────┴───────────────────┴─────────────────────┴──────────────┴───────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = list(range(25,56))\n",
    "\n",
    "actual_hours = df.groupby(\"ILOSTAT\").agg(\n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).mean().alias(\"Mean Hours Worked\"), \n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).median().alias(\"Median Hours Worked\"),\n",
    ").collect()\n",
    "\n",
    "dp_hours = context.query().groupby(\"ILOSTAT\").agg(\n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).dp.mean((1,98), scale = 1/97).alias(\"Mean Hours Worked\"), \n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).dp.median(candidates, 1/97).alias(\"Median Hours Worked\"),\n",
    ").release().collect()\n",
    "\n",
    "hours_cat_df = actual_hours.join(dp_hours, on=[\"ILOSTAT\"]).filter(pl.col(\"ILOSTAT\")==1)\n",
    "\n",
    "hours_cat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Sequential Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where you want to apply sequential composition to an adaptive scenario, you can use the `dp.c.make_sequential_composition` method. There are two ways to implement sequential composition: using transformations and measurements directly and passing in polars queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Sequential Composition with Transformations and Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example references code from a pre-existing compositors tutorial. Learn more about it [here](https://docs.opendp.org/en/nightly/api/user-guide/combinators/compositors.html).\n",
    "\n",
    "The interactive sequential composition doesn't use the compositor we defined at the start of this notebook. Instead, we construct a composition through transformations and measurements, combinator elements present in more lower-level frameworks in the OpenDP library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy Consumption of Entire Composition: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Queryable(Q=AnyMeasurement)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the compositor by specifying parameters\n",
    "sc_meas = dp.c.make_sequential_composition(\n",
    "    input_domain=dp.vector_domain(dp.atom_domain(T=float)),\n",
    "    input_metric=dp.symmetric_distance(),\n",
    "    output_measure=dp.max_divergence(T=float),\n",
    "    #d_in is the upper bound on distances\n",
    "    d_in=1,\n",
    "    #d_mids is the privacy consumption for each query\n",
    "    d_mids=[1., 1., 2.]\n",
    ")\n",
    "\n",
    "#this is the privacy consumption of the entire composition\n",
    "print(\"Privacy Consumption of Entire Composition: \" + str(sc_meas.map(1)))\n",
    "\n",
    "#clean and compile data\n",
    "hours_list = list(np.array(df.select(\n",
    "                                    pl.col(\"HWUSUAL\").\n",
    "                                    fill_null(40.0).\n",
    "                                    fill_nan(40.0).\n",
    "                                    filter(pl.col(\"ILOSTAT\")==1)).\n",
    "                                    collect()\n",
    "                                ).reshape(-1))\n",
    "\n",
    "#this is a queryable that takes in the data similar to the context\n",
    "sc_qbl = sc_meas(hours_list)\n",
    "#we can then apply the queryable to a function of our choosing\n",
    "sc_qbl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP count:  79853\n",
      "DP Mean: 40.20028441533665\n"
     ]
    }
   ],
   "source": [
    "#construct measurement for mean\n",
    "#compute dp median as an input for dp mean \n",
    "input_space = dp.vector_domain(dp.atom_domain(T=float)), dp.symmetric_distance()\n",
    "count_meas = input_space >> dp.t.then_count() >> dp.m.then_laplace(scale=1.0)\n",
    "count_release = sc_qbl(count_meas)\n",
    "print(\"DP count: \",count_release)\n",
    "\n",
    "mean_meas = (\n",
    "    input_space >> \n",
    "    dp.t.then_clamp((0.,79.)) >> \n",
    "    dp.t.then_resize(size=count_release, constant=40.) >> \n",
    "    dp.t.then_mean() >> \n",
    "    dp.m.then_laplace(1.))\n",
    "print(\"DP Mean:\", sc_qbl(mean_meas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Median: 37\n"
     ]
    }
   ],
   "source": [
    "#construct measurement for median\n",
    "discrete_scores = dp.t.make_quantile_score_candidates(dp.vector_domain(dp.atom_domain(T=float)), \n",
    "                                    dp.symmetric_distance(), \n",
    "                                    np.array(candidates).astype(float), \n",
    "                                    0.5)\n",
    "input_space = dp.vector_domain(dp.atom_domain(T=dp.usize), 31), dp.linf_distance(T=dp.usize)\n",
    "select_index_measurement = dp.m.make_report_noisy_max_gumbel(*input_space, scale=1.0, optimize='min')\n",
    "\n",
    "median_meas = discrete_scores >> select_index_measurement >> (lambda index: candidates[index])\n",
    "print(\"DP Median:\", sc_qbl(median_meas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a lot of code! But as you saw, we could change our queries depending on the outputs of other queries, illustrating interactive sequential composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Sequential Composition with Polars Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also implement interactive sequential composition with polars queries! One of the first steps is to specify the domain of our dataframe and add a margin specifying the parameters for the data when it's grouped by `ILOSTAT`. This is **in addition** to specifying it in the compositor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Domain:  FrameDomain(COEFF: f64, QUARTER: i64, REFYEAR: i64, REFWEEK: i64, INTWEEK: f64, COUNTRY: str, DEGURBA: f64, HHINST: f64, INTWAVE: i64, INTQUEST: i64, REM: i64, YEAR: i64, HHPRIV: i64, SEX: i64, AGE: f64, NATIONAL: str, YEARESID: f64, COUNTRYB: str, PROXY: f64, NOWKREAS: i64, STAPRO: f64, SIGNISAL: i64, COUNTRYW: str, YSTARTWK: f64, MSTARTWK: f64, FTPT: f64, TEMP: f64, TEMPDUR: f64, HWUSUAL: f64, HWACTUAL: f64, HWOVERP: f64, HWOVERPU: f64, HOURREAS: f64, WISHMORE: f64, HWWISH: f64, LOOKOJ: i64, EXIST2J: f64, STAPRO2J: f64, HWACTUA2: f64, EXISTPR: f64, YEARPR: f64, MONTHPR: f64, STAPROPR: f64, SEEKWORK: i64, SEEKTYPE: f64, SEEKDUR: f64, METHODA: i64, METHODB: i64, METHODC: i64, METHODD: i64, METHODE: i64, METHODF: i64, METHODG: i64, METHODH: i64, METHODI: i64, METHODJ: i64, METHODK: i64, METHODL: i64, METHODM: i64, WANTWORK: f64, AVAILBLE: i64, EDUCSTAT: f64, EDUCLEVL: f64, COURATT: f64, COURLEN: f64, ILOSTAT: i64, ISCO1D: f64, ISCOPR1D: f64, DURUNE: f64, EDUC4WN: f64, HATLEV1D: str, STARTIME: f64, LEAVCLAS: f64, NACE1D: str, NACE2J1D: str, NACEPR1D: str, HHTYPE: i64; margins=[{\"ILOSTAT\"}])\n"
     ]
    }
   ],
   "source": [
    "#get the domain of the datafarame\n",
    "df_domain = dp.domain_of(df, infer=True)\n",
    "#specify the parameters when grouped by Working cateory\n",
    "df_domain = dp.with_margin(df_domain, by=[\"ILOSTAT\"], \n",
    "                           public_info=\"lengths\", \n",
    "                           max_partition_length=50, \n",
    "                           max_num_partitions=3)\n",
    "print(\"DF Domain: \",df_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our proposed plan, which are the same queries that we worked with in noninteractive sequential composition. However, this time we aren't actually releasing or collecting any results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>naive plan: (run <b>LazyFrame.explain(optimized=True)</b> to see the optimized plan)</i>\n",
       "    <p></p>\n",
       "    <div>AGGREGATE<p></p>\t[[(col(\"HWUSUAL\").fill_null([40.0]).clip([1, 98]).sum()./Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/opendp/lib/opendp.abi3.so:noise()) / (len())].alias(\"Mean Hours Worked\"), col(\"HWUSUAL\").fill_null([40.0])./Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/opendp/lib/opendp.abi3.so:discrete_quantile_score()./Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/opendp/lib/opendp.abi3.so:report_noisy_max_gumbel()./Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/opendp/lib/opendp.abi3.so:index_candidates().alias(\"Median Hours Worked\")] BY [col(\"ILOSTAT\")] FROM<p></p>  DF [\"COEFF\", \"QUARTER\", \"REFYEAR\", \"REFWEEK\"]; PROJECT */77 COLUMNS; SELECTION: \"None\"</div>"
      ],
      "text/plain": [
       "<wrap [3 cols, {\"ILOSTAT\": Int64 … \"Median Hours Worked\": Int64}] at 0x16D8417C0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define polars queries\n",
    "proposed_plan = context.query().groupby(\"ILOSTAT\").agg(\n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).dp.mean((1,98), scale = 8).alias(\"Mean Hours Worked\"), \n",
    "    pl.col(\"HWUSUAL\").fill_null(40.0).dp.median(candidates, 8).alias(\"Median Hours Worked\"),\n",
    ")\n",
    "proposed_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up a measurement to execute the sequential creaties and pass in our `df_domain` and `proposed_plan`. We can pass our data to this measurement and the collect our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 3)\n",
      "┌─────────┬───────────────────┬─────────────────────┐\n",
      "│ ILOSTAT ┆ Mean Hours Worked ┆ Median Hours Worked │\n",
      "│ ---     ┆ ---               ┆ ---                 │\n",
      "│ i64     ┆ f64               ┆ i64                 │\n",
      "╞═════════╪═══════════════════╪═════════════════════╡\n",
      "│ 1       ┆ 37.671921         ┆ 29                  │\n",
      "└─────────┴───────────────────┴─────────────────────┘\n",
      "<opendp.polars.OnceFrame object at 0x12ea6f740>\n"
     ]
    }
   ],
   "source": [
    "# IN SERVER\n",
    "m_polars = dp.m.make_private_lazyframe(\n",
    "    input_domain=df_domain, \n",
    "    input_metric=dp.symmetric_distance(), \n",
    "    output_measure=dp.max_divergence(T=float), \n",
    "    lazyframe=proposed_plan, \n",
    "    global_scale=1.\n",
    ")\n",
    "\n",
    "df_release = m_polars(df).collect().filter(pl.col(\"ILOSTAT\")==1)\n",
    "print(df_release)\n",
    "#TODO: more explanation on the different steps here\n",
    "\n",
    "m_comp = dp.c.make_sequential_composition(\n",
    "    m_polars.input_domain,\n",
    "    m_polars.input_metric,\n",
    "    m_polars.output_measure,\n",
    "    2, \n",
    "    [18.0, 18.0]\n",
    ")\n",
    "\n",
    "qbl_comp = m_comp(df)\n",
    "once_frame = qbl_comp(m_polars)\n",
    "print(qbl_comp(m_polars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel composition can be viewed as an alternative to sequential composition since it's another way to calculate a bound on the total privacy cost of multiple queries. \n",
    "\n",
    "Parallel composition involves partitioning the input dataset into disjoint partitions and applying a differentially private mechanism on each chunk independent of all other chunks. Assuming each individual is represented once in the dataset, their data will appear in exactly one chunk. If there are $k$ chunks, there will be $k$ runs of the differentially private mechanisms.\n",
    "\n",
    "To apply parallel composition, we need to set up our margin or define our query to allow each individual to influence at most 1 partition, or appear at most in 1 chunk. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noninteractive Parallel Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, each individual is represented just one each year, quarter, and labor status. Moreover, this example also satisfies the properties of noninteractive sequential composition since all the queries are executed simultaneously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>YEAR</th><th>QUARTER</th><th>ILOSTAT</th><th>Mean Hours Worked</th><th>Median Hours Worked</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>2004</td><td>1</td><td>1</td><td>37.231225</td><td>25</td></tr><tr><td>2004</td><td>2</td><td>1</td><td>41.136433</td><td>55</td></tr><tr><td>2004</td><td>3</td><td>1</td><td>37.531945</td><td>55</td></tr><tr><td>2004</td><td>4</td><td>1</td><td>37.375663</td><td>55</td></tr><tr><td>2005</td><td>1</td><td>1</td><td>35.841911</td><td>55</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2012</td><td>4</td><td>1</td><td>38.014647</td><td>25</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>37.630491</td><td>25</td></tr><tr><td>2013</td><td>2</td><td>1</td><td>35.786751</td><td>55</td></tr><tr><td>2013</td><td>3</td><td>1</td><td>38.219257</td><td>55</td></tr><tr><td>2013</td><td>4</td><td>1</td><td>37.850275</td><td>25</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 5)\n",
       "┌──────┬─────────┬─────────┬───────────────────┬─────────────────────┐\n",
       "│ YEAR ┆ QUARTER ┆ ILOSTAT ┆ Mean Hours Worked ┆ Median Hours Worked │\n",
       "│ ---  ┆ ---     ┆ ---     ┆ ---               ┆ ---                 │\n",
       "│ i64  ┆ i64     ┆ i64     ┆ f64               ┆ i64                 │\n",
       "╞══════╪═════════╪═════════╪═══════════════════╪═════════════════════╡\n",
       "│ 2004 ┆ 1       ┆ 1       ┆ 37.231225         ┆ 25                  │\n",
       "│ 2004 ┆ 2       ┆ 1       ┆ 41.136433         ┆ 55                  │\n",
       "│ 2004 ┆ 3       ┆ 1       ┆ 37.531945         ┆ 55                  │\n",
       "│ 2004 ┆ 4       ┆ 1       ┆ 37.375663         ┆ 55                  │\n",
       "│ 2005 ┆ 1       ┆ 1       ┆ 35.841911         ┆ 55                  │\n",
       "│ …    ┆ …       ┆ …       ┆ …                 ┆ …                   │\n",
       "│ 2012 ┆ 4       ┆ 1       ┆ 38.014647         ┆ 25                  │\n",
       "│ 2013 ┆ 1       ┆ 1       ┆ 37.630491         ┆ 25                  │\n",
       "│ 2013 ┆ 2       ┆ 1       ┆ 35.786751         ┆ 55                  │\n",
       "│ 2013 ┆ 3       ┆ 1       ┆ 38.219257         ┆ 55                  │\n",
       "│ 2013 ┆ 4       ┆ 1       ┆ 37.850275         ┆ 25                  │\n",
       "└──────┴─────────┴─────────┴───────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.query().groupby([\"YEAR\",\"QUARTER\",\"ILOSTAT\"]).agg(\n",
    "    pl.col(\"HWUSUAL\").fill_null(74).dp.mean((1,98)).alias(\"Mean Hours Worked\"),\n",
    "    pl.col(\"HWUSUAL\").fill_null(74).dp.median((25,55)).alias(\"Median Hours Worked\")\n",
    ").release().collect().filter(pl.col(\"ILOSTAT\")==1).sort([\"YEAR\", \"QUARTER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Parallel Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll illustrate interactive parallel composition using the polars-interactivity methods. Much of the code is similar to interactive sequential composition. The primary change is the domain and proposed plan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (40, 5)\n",
      "┌──────┬─────────┬─────────┬───────────────────┬─────────────────────┐\n",
      "│ YEAR ┆ QUARTER ┆ ILOSTAT ┆ Mean Hours Worked ┆ Median Hours Worked │\n",
      "│ ---  ┆ ---     ┆ ---     ┆ ---               ┆ ---                 │\n",
      "│ i64  ┆ i64     ┆ i64     ┆ f64               ┆ i64                 │\n",
      "╞══════╪═════════╪═════════╪═══════════════════╪═════════════════════╡\n",
      "│ 2004 ┆ 4       ┆ 1       ┆ 38.398011         ┆ 25                  │\n",
      "│ 2005 ┆ 4       ┆ 1       ┆ 38.049643         ┆ 25                  │\n",
      "│ 2006 ┆ 2       ┆ 1       ┆ 37.584            ┆ 55                  │\n",
      "│ 2010 ┆ 4       ┆ 1       ┆ 38.229102         ┆ 25                  │\n",
      "│ 2011 ┆ 2       ┆ 1       ┆ 37.648676         ┆ 25                  │\n",
      "│ …    ┆ …       ┆ …       ┆ …                 ┆ …                   │\n",
      "│ 2006 ┆ 1       ┆ 1       ┆ 38.198405         ┆ 55                  │\n",
      "│ 2012 ┆ 2       ┆ 1       ┆ 37.883794         ┆ 25                  │\n",
      "│ 2011 ┆ 4       ┆ 1       ┆ 38.575118         ┆ 25                  │\n",
      "│ 2010 ┆ 2       ┆ 1       ┆ 37.918881         ┆ 25                  │\n",
      "│ 2012 ┆ 3       ┆ 1       ┆ 38.094774         ┆ 25                  │\n",
      "└──────┴─────────┴─────────┴───────────────────┴─────────────────────┘\n",
      "<opendp.polars.OnceFrame object at 0x16e047cb0>\n"
     ]
    }
   ],
   "source": [
    "#get the domain of the datafarame\n",
    "lf_domain = dp.domain_of(df, infer=True)\n",
    "lf_domain = dp.with_margin(lf_domain, by=[\"YEAR\",\"QUARTER\",\"ILOSTAT\"], \n",
    "                           public_info=\"lengths\", \n",
    "                           max_partition_length=50, \n",
    "                           max_num_partitions=3)\n",
    "\n",
    "proposed_plan = context.query().groupby([\"YEAR\",\"QUARTER\",\"ILOSTAT\"]).agg(\n",
    "    pl.col(\"HWUSUAL\").fill_null(74).dp.mean((1,98), 8).alias(\"Mean Hours Worked\"),\n",
    "    pl.col(\"HWUSUAL\").fill_null(74).dp.median((25,55), 8).alias(\"Median Hours Worked\")\n",
    ")\n",
    "# IN SERVER\n",
    "m_polars = dp.m.make_private_lazyframe(\n",
    "    input_domain=lf_domain, \n",
    "    input_metric=dp.symmetric_distance(), \n",
    "    output_measure=dp.max_divergence(T=float), \n",
    "    lazyframe=proposed_plan, \n",
    "    global_scale=1.\n",
    ")\n",
    "\n",
    "df_release = m_polars(df).collect().filter(pl.col(\"ILOSTAT\")==1)\n",
    "print(df_release)\n",
    "\n",
    "m_comp = dp.c.make_sequential_composition(\n",
    "    m_polars.input_domain,\n",
    "    m_polars.input_metric,\n",
    "    m_polars.output_measure,\n",
    "    2, \n",
    "    [18.0, 18.0]\n",
    ")\n",
    "\n",
    "\n",
    "qbl_comp = m_comp(df)\n",
    "print(qbl_comp(m_polars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Sequential and Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, parallel composition provides a much better bound than sequential composition. The total privacy loss for parallel composition is just ε since there are $k$ disjoint partitions and each of them also satisfies ε-dp. With sequential composition, the total privacy loss is $k$ * ε since we would run each query $k$ times.\n",
    "\n",
    "However, one disadvantage of parallel composition is that has the dataset is split into more parts, each part will have a weaker signal and hence less accuracy. \n",
    "\n",
    "Additionally, in cases where we want statistics that reference the whole dataset, sequential composition may be a better fit. \n",
    "\n",
    "Therefore, the recommendation is to use parallel composition unless the partitions are too small to provide adequate accuracy or the entire data needs to be referenced for the calculated statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrated: \n",
    "- The difference between interactive and noninteractive queries. \n",
    "- The definition and properties of sequential composition. \n",
    "- How to implement noninteractive sequential composition with polars, interactive sequential composition using transformations and measurements directly, and interactive sequential composition using polars queries. \n",
    "- The definition and properties of parallel composition. \n",
    "- How to implement noninterative parallel composition and interactive parallel composition. \n",
    "- The differences between parallel and sequential composition and recommendations for when to choose which. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
